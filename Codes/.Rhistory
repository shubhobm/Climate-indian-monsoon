n.sig = 2
beta = c(runif(n.sig,1,8),rep(0,p-n.sig))
beta.names1 = c("x1x2")
beta.names2 = c("x2x1")
X.names = paste0(rep("x",p), 1:p)
d = read.table("../data/charliesim.txt", header=T)
X = as.matrix(d[sample(1:nrow(d),100,replace=F),1:p])
form = as.formula(paste0("y~", paste(X.names, collapse="+")))
n.AIC.bk = 0
n.AIC.all = 0
n.BIC.bk = 0
n.BIC.all = 0
?sample
for(iter in 1:n.iter){
#X = matrix(rnorm(n*p), ncol=p)
y = X %*% beta + sig*rnorm(n)*sample(1:3, n, replace=F)
lmod = lm(form, data=data.frame(X))
selmod = step(lmod, direction="backward", k=log(n), trace=0)
selnames = names(selmod$coef)[-1]
name.paste = paste0(selnames, collapse="")
#print(name.paste)
if(name.paste==beta.names1 | name.paste==beta.names2){
n.BIC.bk = n.BIC.bk + 1
}
selmod = step(lmod, direction="backward", trace=0)
selnames = names(selmod$coef)[-1]
name.paste = paste0(selnames, collapse="")
#print(name.paste)
if(name.paste==beta.names1 | name.paste==beta.names2){
n.AIC.bk = n.AIC.bk + 1
}
# all subsets regression BIC
subsetObj = summary(regsubsets(X,y,nvmax=p))
bicvals = subsetObj$bic
best.ind = which(subsetObj$which[which.min(bicvals),-1])
name.paste = paste0(X.names[best.ind], collapse="")
#   print(paste0(iter,name.paste))
if(name.paste==beta.names1 | name.paste==beta.names2){
n.BIC.all = n.BIC.all + 1
}
# all subsets regression AIC
aicvals = subsetObj$cp
best.ind = which(subsetObj$which[which.min(aicvals),-1])
name.paste = paste0(X.names[best.ind], collapse="")
#   print(paste0(iter,name.paste))
if(name.paste==beta.names1 | name.paste==beta.names2){
n.AIC.all = n.AIC.all + 1
}
}
n.Cn = rep(0,3)
for(nsd in 1:3){
set.seed(10052015)
pb = txtProgressBar(0,n.iter)
for(iter in 1:n.iter){
# depth model selection
Const.P = list()
Const.beta = list()
Const.r = list()
for(j in 1:p){
Xj = X[,-j]
Const.P[[j]] = solve(t(Xj) %*% Xj) %*% t(Xj)
Const.beta[[j]] = Const.P[[j]] %*% y
Const.r[[j]] = y - Xj %*% Const.beta[[j]]
}
P = solve(t(X) %*% X) %*% t(X)
beta.hat = P %*% y
r = y - X %*% beta.hat
# matrix of full model estimates: Fn is approx by Fn^b1
beta.mat = matrix(0, nrow=nboot, ncol=p)
for(i in 1:nboot){
beta.mat[i,] = beta.hat + P %*% (sdn[nsd]*rnorm(n)*r)
}
# get truncated estimates: beta_alpha approx by beta_alpha^b
SSPmat.d = matrix(0, nrow=nboot, ncol=p+1)
for(i in 1:nboot){
for(j in 1:p){
ibeta.j = Const.beta[[j]] + Const.P[[j]] %*% (sdn[nsd]*rnorm(n)*Const.r[[j]])
# get depth-based criterion
ibeta.j.full = rep(0,p)
ibeta.j.full[-j] = ibeta.j
SSPmat.d[i,j] = mdepth.TD(t(as.matrix(ibeta.j.full)), beta.mat)$dep
#SSPmat.d[i,p+1] = 1/(1 + t(as.numeric(ibeta.j.full) - beta) %*% XtX.inv %*% (as.numeric(ibeta.j.full) - beta))
}
# for full model
ibeta = beta.hat + P %*% (sdn[nsd]*rnorm(n)*r)
SSPmat.d[i,p+1] = mdepth.TD(t(ibeta), beta.mat)$dep
#SSPmat.d[i,p+1] = 1/(1 + t(as.numeric(ibeta) - beta) %*% XtX.inv %*% (as.numeric(ibeta) - beta))
}
Cn.vec = apply(SSPmat.d, 2, mean)
which.sel = which(Cn.vec[-(p+1)] < Cn.vec[p+1])
name.Cn = paste(X.names[which.sel], collapse="")
# print(paste(nsd, iter, name.Cn))
if(name.Cn==beta.names1 | name.Cn==beta.names2){
n.Cn[nsd] = n.Cn[nsd] + 1
}
setTxtProgressBar(pb,iter)
}
close(pb)
}
n.AIC.bk / n.iter
n.AIC.all / n.iter
n.BIC.bk / n.iter
n.BIC.all / n.iter
n.Cn / n.iter
for(iter in 1:n.iter){
#X = matrix(rnorm(n*p), ncol=p)
y = X %*% beta + sig*rnorm(n)*sample(1:3, n, replace=T)
lmod = lm(form, data=data.frame(X))
selmod = step(lmod, direction="backward", k=log(n), trace=0)
selnames = names(selmod$coef)[-1]
name.paste = paste0(selnames, collapse="")
#print(name.paste)
if(name.paste==beta.names1 | name.paste==beta.names2){
n.BIC.bk = n.BIC.bk + 1
}
selmod = step(lmod, direction="backward", trace=0)
selnames = names(selmod$coef)[-1]
name.paste = paste0(selnames, collapse="")
#print(name.paste)
if(name.paste==beta.names1 | name.paste==beta.names2){
n.AIC.bk = n.AIC.bk + 1
}
# all subsets regression BIC
subsetObj = summary(regsubsets(X,y,nvmax=p))
bicvals = subsetObj$bic
best.ind = which(subsetObj$which[which.min(bicvals),-1])
name.paste = paste0(X.names[best.ind], collapse="")
#   print(paste0(iter,name.paste))
if(name.paste==beta.names1 | name.paste==beta.names2){
n.BIC.all = n.BIC.all + 1
}
# all subsets regression AIC
aicvals = subsetObj$cp
best.ind = which(subsetObj$which[which.min(aicvals),-1])
name.paste = paste0(X.names[best.ind], collapse="")
#   print(paste0(iter,name.paste))
if(name.paste==beta.names1 | name.paste==beta.names2){
n.AIC.all = n.AIC.all + 1
}
}
n.Cn = rep(0,3)
for(nsd in 1:3){
set.seed(10052015)
pb = txtProgressBar(0,n.iter)
for(iter in 1:n.iter){
# depth model selection
Const.P = list()
Const.beta = list()
Const.r = list()
for(j in 1:p){
Xj = X[,-j]
Const.P[[j]] = solve(t(Xj) %*% Xj) %*% t(Xj)
Const.beta[[j]] = Const.P[[j]] %*% y
Const.r[[j]] = y - Xj %*% Const.beta[[j]]
}
P = solve(t(X) %*% X) %*% t(X)
beta.hat = P %*% y
r = y - X %*% beta.hat
# matrix of full model estimates: Fn is approx by Fn^b1
beta.mat = matrix(0, nrow=nboot, ncol=p)
for(i in 1:nboot){
beta.mat[i,] = beta.hat + P %*% (sdn[nsd]*rnorm(n)*r)
}
# get truncated estimates: beta_alpha approx by beta_alpha^b
SSPmat.d = matrix(0, nrow=nboot, ncol=p+1)
for(i in 1:nboot){
for(j in 1:p){
ibeta.j = Const.beta[[j]] + Const.P[[j]] %*% (sdn[nsd]*rnorm(n)*Const.r[[j]])
# get depth-based criterion
ibeta.j.full = rep(0,p)
ibeta.j.full[-j] = ibeta.j
SSPmat.d[i,j] = mdepth.TD(t(as.matrix(ibeta.j.full)), beta.mat)$dep
#SSPmat.d[i,p+1] = 1/(1 + t(as.numeric(ibeta.j.full) - beta) %*% XtX.inv %*% (as.numeric(ibeta.j.full) - beta))
}
# for full model
ibeta = beta.hat + P %*% (sdn[nsd]*rnorm(n)*r)
SSPmat.d[i,p+1] = mdepth.TD(t(ibeta), beta.mat)$dep
#SSPmat.d[i,p+1] = 1/(1 + t(as.numeric(ibeta) - beta) %*% XtX.inv %*% (as.numeric(ibeta) - beta))
}
Cn.vec = apply(SSPmat.d, 2, mean)
which.sel = which(Cn.vec[-(p+1)] < Cn.vec[p+1])
name.Cn = paste(X.names[which.sel], collapse="")
# print(paste(nsd, iter, name.Cn))
if(name.Cn==beta.names1 | name.Cn==beta.names2){
n.Cn[nsd] = n.Cn[nsd] + 1
}
setTxtProgressBar(pb,iter)
}
close(pb)
}
n.AIC.bk / n.iter
n.AIC.all / n.iter
n.BIC.bk / n.iter
n.BIC.all / n.iter
plot(lmod)
y = X %*% beta + sig*rnorm(n)*.1*X[,1]^2
ploy(y,X[,1])
plot(y,X[,1])
y = X %*% beta + sig*rnorm(n)*.5*X[,1]^2
plot(y,X[,1])
for(iter in 1:n.iter){
#X = matrix(rnorm(n*p), ncol=p)
y = X %*% beta + sig*rnorm(n)*.2*X[,1]^2
lmod = lm(form, data=data.frame(X))
selmod = step(lmod, direction="backward", k=log(n), trace=0)
selnames = names(selmod$coef)[-1]
name.paste = paste0(selnames, collapse="")
#print(name.paste)
if(name.paste==beta.names1 | name.paste==beta.names2){
n.BIC.bk = n.BIC.bk + 1
}
selmod = step(lmod, direction="backward", trace=0)
selnames = names(selmod$coef)[-1]
name.paste = paste0(selnames, collapse="")
#print(name.paste)
if(name.paste==beta.names1 | name.paste==beta.names2){
n.AIC.bk = n.AIC.bk + 1
}
# all subsets regression BIC
subsetObj = summary(regsubsets(X,y,nvmax=p))
bicvals = subsetObj$bic
best.ind = which(subsetObj$which[which.min(bicvals),-1])
name.paste = paste0(X.names[best.ind], collapse="")
#   print(paste0(iter,name.paste))
if(name.paste==beta.names1 | name.paste==beta.names2){
n.BIC.all = n.BIC.all + 1
}
# all subsets regression AIC
aicvals = subsetObj$cp
best.ind = which(subsetObj$which[which.min(aicvals),-1])
name.paste = paste0(X.names[best.ind], collapse="")
#   print(paste0(iter,name.paste))
if(name.paste==beta.names1 | name.paste==beta.names2){
n.AIC.all = n.AIC.all + 1
}
}
n.AIC.bk / n.iter
n.AIC.all / n.iter
n.BIC.bk / n.iter
n.BIC.all / n.iter
n.AIC.bk = 0
n.AIC.all = 0
n.BIC.bk = 0
n.BIC.all = 0
for(iter in 1:n.iter){
#X = matrix(rnorm(n*p), ncol=p)
y = X %*% beta + sig*rnorm(n)*.2*X[,1]^2
lmod = lm(form, data=data.frame(X))
selmod = step(lmod, direction="backward", k=log(n), trace=0)
selnames = names(selmod$coef)[-1]
name.paste = paste0(selnames, collapse="")
#print(name.paste)
if(name.paste==beta.names1 | name.paste==beta.names2){
n.BIC.bk = n.BIC.bk + 1
}
selmod = step(lmod, direction="backward", trace=0)
selnames = names(selmod$coef)[-1]
name.paste = paste0(selnames, collapse="")
#print(name.paste)
if(name.paste==beta.names1 | name.paste==beta.names2){
n.AIC.bk = n.AIC.bk + 1
}
# all subsets regression BIC
subsetObj = summary(regsubsets(X,y,nvmax=p))
bicvals = subsetObj$bic
best.ind = which(subsetObj$which[which.min(bicvals),-1])
name.paste = paste0(X.names[best.ind], collapse="")
#   print(paste0(iter,name.paste))
if(name.paste==beta.names1 | name.paste==beta.names2){
n.BIC.all = n.BIC.all + 1
}
# all subsets regression AIC
aicvals = subsetObj$cp
best.ind = which(subsetObj$which[which.min(aicvals),-1])
name.paste = paste0(X.names[best.ind], collapse="")
#   print(paste0(iter,name.paste))
if(name.paste==beta.names1 | name.paste==beta.names2){
n.AIC.all = n.AIC.all + 1
}
}
n.AIC.bk / n.iter
n.AIC.all / n.iter
n.BIC.bk / n.iter
n.BIC.all / n.iter
n.AIC.bk = 0
n.AIC.all = 0
n.BIC.bk = 0
n.BIC.all = 0
for(iter in 1:n.iter){
#X = matrix(rnorm(n*p), ncol=p)
y = X %*% beta + sig*rnorm(n)*X[,1]^2
lmod = lm(form, data=data.frame(X))
selmod = step(lmod, direction="backward", k=log(n), trace=0)
selnames = names(selmod$coef)[-1]
name.paste = paste0(selnames, collapse="")
#print(name.paste)
if(name.paste==beta.names1 | name.paste==beta.names2){
n.BIC.bk = n.BIC.bk + 1
}
selmod = step(lmod, direction="backward", trace=0)
selnames = names(selmod$coef)[-1]
name.paste = paste0(selnames, collapse="")
#print(name.paste)
if(name.paste==beta.names1 | name.paste==beta.names2){
n.AIC.bk = n.AIC.bk + 1
}
# all subsets regression BIC
subsetObj = summary(regsubsets(X,y,nvmax=p))
bicvals = subsetObj$bic
best.ind = which(subsetObj$which[which.min(bicvals),-1])
name.paste = paste0(X.names[best.ind], collapse="")
#   print(paste0(iter,name.paste))
if(name.paste==beta.names1 | name.paste==beta.names2){
n.BIC.all = n.BIC.all + 1
}
# all subsets regression AIC
aicvals = subsetObj$cp
best.ind = which(subsetObj$which[which.min(aicvals),-1])
name.paste = paste0(X.names[best.ind], collapse="")
#   print(paste0(iter,name.paste))
if(name.paste==beta.names1 | name.paste==beta.names2){
n.AIC.all = n.AIC.all + 1
}
}
n.AIC.bk / n.iter
n.AIC.all / n.iter
n.BIC.bk / n.iter
n.BIC.all / n.iter
plot(y,X[,1])
n.Cn = rep(0,3)
for(nsd in 1:3){
set.seed(10052015)
#pb = txtProgressBar(0,n.iter)
for(iter in 1:n.iter){
# depth model selection
Const.P = list()
Const.beta = list()
Const.r = list()
for(j in 1:p){
Xj = X[,-j]
Const.P[[j]] = solve(t(Xj) %*% Xj) %*% t(Xj)
Const.beta[[j]] = Const.P[[j]] %*% y
Const.r[[j]] = y - Xj %*% Const.beta[[j]]
}
P = solve(t(X) %*% X) %*% t(X)
beta.hat = P %*% y
r = y - X %*% beta.hat
# matrix of full model estimates: Fn is approx by Fn^b1
beta.mat = matrix(0, nrow=nboot, ncol=p)
for(i in 1:nboot){
beta.mat[i,] = beta.hat + P %*% (sdn[nsd]*rnorm(n)*r)
}
# get truncated estimates: beta_alpha approx by beta_alpha^b
SSPmat.d = matrix(0, nrow=nboot, ncol=p+1)
for(i in 1:nboot){
for(j in 1:p){
ibeta.j = Const.beta[[j]] + Const.P[[j]] %*% (sdn[nsd]*rnorm(n)*Const.r[[j]])
# get depth-based criterion
ibeta.j.full = rep(0,p)
ibeta.j.full[-j] = ibeta.j
SSPmat.d[i,j] = mdepth.TD(t(as.matrix(ibeta.j.full)), beta.mat)$dep
#SSPmat.d[i,p+1] = 1/(1 + t(as.numeric(ibeta.j.full) - beta) %*% XtX.inv %*% (as.numeric(ibeta.j.full) - beta))
}
# for full model
ibeta = beta.hat + P %*% (sdn[nsd]*rnorm(n)*r)
SSPmat.d[i,p+1] = mdepth.TD(t(ibeta), beta.mat)$dep
#SSPmat.d[i,p+1] = 1/(1 + t(as.numeric(ibeta) - beta) %*% XtX.inv %*% (as.numeric(ibeta) - beta))
}
Cn.vec = apply(SSPmat.d, 2, mean)
which.sel = which(Cn.vec[-(p+1)] < Cn.vec[p+1])
name.Cn = paste(X.names[which.sel], collapse="")
print(paste(nsd, iter, name.Cn))
if(name.Cn==beta.names1 | name.Cn==beta.names2){
n.Cn[nsd] = n.Cn[nsd] + 1
}
#setTxtProgressBar(pb,iter)
}
#close(pb)
}
n.AIC.bk = 0
n.AIC.all = 0
n.BIC.bk = 0
n.BIC.all = 0
for(iter in 1:n.iter){
#X = matrix(rnorm(n*p), ncol=p)
y = X %*% beta + sig*rnorm(n)*.(2*X[,1]^2 - .5*X[,2])
lmod = lm(form, data=data.frame(X))
selmod = step(lmod, direction="backward", k=log(n), trace=0)
selnames = names(selmod$coef)[-1]
name.paste = paste0(selnames, collapse="")
#print(name.paste)
if(name.paste==beta.names1 | name.paste==beta.names2){
n.BIC.bk = n.BIC.bk + 1
}
selmod = step(lmod, direction="backward", trace=0)
selnames = names(selmod$coef)[-1]
name.paste = paste0(selnames, collapse="")
#print(name.paste)
if(name.paste==beta.names1 | name.paste==beta.names2){
n.AIC.bk = n.AIC.bk + 1
}
# all subsets regression BIC
subsetObj = summary(regsubsets(X,y,nvmax=p))
bicvals = subsetObj$bic
best.ind = which(subsetObj$which[which.min(bicvals),-1])
name.paste = paste0(X.names[best.ind], collapse="")
#   print(paste0(iter,name.paste))
if(name.paste==beta.names1 | name.paste==beta.names2){
n.BIC.all = n.BIC.all + 1
}
# all subsets regression AIC
aicvals = subsetObj$cp
best.ind = which(subsetObj$which[which.min(aicvals),-1])
name.paste = paste0(X.names[best.ind], collapse="")
#   print(paste0(iter,name.paste))
if(name.paste==beta.names1 | name.paste==beta.names2){
n.AIC.all = n.AIC.all + 1
}
}
for(iter in 1:n.iter){
#X = matrix(rnorm(n*p), ncol=p)
y = X %*% beta + sig*rnorm(n)*(2*X[,1]^2 - .5*X[,2])
lmod = lm(form, data=data.frame(X))
selmod = step(lmod, direction="backward", k=log(n), trace=0)
selnames = names(selmod$coef)[-1]
name.paste = paste0(selnames, collapse="")
#print(name.paste)
if(name.paste==beta.names1 | name.paste==beta.names2){
n.BIC.bk = n.BIC.bk + 1
}
selmod = step(lmod, direction="backward", trace=0)
selnames = names(selmod$coef)[-1]
name.paste = paste0(selnames, collapse="")
#print(name.paste)
if(name.paste==beta.names1 | name.paste==beta.names2){
n.AIC.bk = n.AIC.bk + 1
}
# all subsets regression BIC
subsetObj = summary(regsubsets(X,y,nvmax=p))
bicvals = subsetObj$bic
best.ind = which(subsetObj$which[which.min(bicvals),-1])
name.paste = paste0(X.names[best.ind], collapse="")
#   print(paste0(iter,name.paste))
if(name.paste==beta.names1 | name.paste==beta.names2){
n.BIC.all = n.BIC.all + 1
}
# all subsets regression AIC
aicvals = subsetObj$cp
best.ind = which(subsetObj$which[which.min(aicvals),-1])
name.paste = paste0(X.names[best.ind], collapse="")
#   print(paste0(iter,name.paste))
if(name.paste==beta.names1 | name.paste==beta.names2){
n.AIC.all = n.AIC.all + 1
}
}
n.AIC.bk / n.iter
n.AIC.all / n.iter
n.BIC.bk / n.iter
n.BIC.all / n.iter
plot(y,X[,1])
plot(y,X[,2])
plot(lmod)
n.Cn = rep(0,3)
for(nsd in 1:3){
set.seed(10052015)
#pb = txtProgressBar(0,n.iter)
for(iter in 1:n.iter){
# depth model selection
Const.P = list()
Const.beta = list()
Const.r = list()
for(j in 1:p){
Xj = X[,-j]
Const.P[[j]] = solve(t(Xj) %*% Xj) %*% t(Xj)
Const.beta[[j]] = Const.P[[j]] %*% y
Const.r[[j]] = y - Xj %*% Const.beta[[j]]
}
P = solve(t(X) %*% X) %*% t(X)
beta.hat = P %*% y
r = y - X %*% beta.hat
# matrix of full model estimates: Fn is approx by Fn^b1
beta.mat = matrix(0, nrow=nboot, ncol=p)
for(i in 1:nboot){
beta.mat[i,] = beta.hat + P %*% (sdn[nsd]*rnorm(n)*r)
}
# get truncated estimates: beta_alpha approx by beta_alpha^b
SSPmat.d = matrix(0, nrow=nboot, ncol=p+1)
for(i in 1:nboot){
for(j in 1:p){
ibeta.j = Const.beta[[j]] + Const.P[[j]] %*% (sdn[nsd]*rnorm(n)*Const.r[[j]])
# get depth-based criterion
ibeta.j.full = rep(0,p)
ibeta.j.full[-j] = ibeta.j
SSPmat.d[i,j] = mdepth.TD(t(as.matrix(ibeta.j.full)), beta.mat)$dep
#SSPmat.d[i,p+1] = 1/(1 + t(as.numeric(ibeta.j.full) - beta) %*% XtX.inv %*% (as.numeric(ibeta.j.full) - beta))
}
# for full model
ibeta = beta.hat + P %*% (sdn[nsd]*rnorm(n)*r)
SSPmat.d[i,p+1] = mdepth.TD(t(ibeta), beta.mat)$dep
#SSPmat.d[i,p+1] = 1/(1 + t(as.numeric(ibeta) - beta) %*% XtX.inv %*% (as.numeric(ibeta) - beta))
}
Cn.vec = apply(SSPmat.d, 2, mean)
which.sel = which(Cn.vec[-(p+1)] < Cn.vec[p+1])
name.Cn = paste(X.names[which.sel], collapse="")
print(paste(nsd, iter, name.Cn))
if(name.Cn==beta.names1 | name.Cn==beta.names2){
n.Cn[nsd] = n.Cn[nsd] + 1
}
#setTxtProgressBar(pb,iter)
}
#close(pb)
}
